#!/usr/bin/perl
#
# Script to record cron job execution and archive output back to a 
# central webserver as text files using HTTP PUTs.
#

use strict;
use warnings;
use File::Basename;
use Getopt::Long qw(:config no_ignore_case bundling require_order);
use Config::Tiny;
use Sys::Hostname;
use Time::Piece;
use Digest::MD5 qw(md5_hex);
use IPC::Run3;
use LWP::UserAgent;
use HTTP::Request;

sub usage {
  die "usage: " . basename($0) . " [--always|--stream] [--passthru] [-n] [-v] <command> <args>\n";
}

my $verbose = 0;
my $config_file = $ENV{CRONOLOGUE_CONF} || '/etc/cronologue.conf';
my ($help, $noop, $stream, $always, $passthru);
usage unless GetOptions(
  'help|h|?'        => \$help,
  'verbose|v+'      => \$verbose,
  'noop|n'          => \$noop,
  'stream|s'        => \$stream,
  'always|a'        => \$always,
  'passthru|p'      => \$passthru,
  'config|c=s'      => \$config_file,
);
usage if $help;
usage unless @ARGV;
usage "Cannot specify both --always and --stream\n"
  if $stream && $always;
$verbose ||= 1 if $noop;

my @cmd = @ARGV;
my $cmd = \@cmd;
# If a single composite argument, pass to run3 as a string (for shell eval)
if (@cmd == 1 && $cmd[0] =~ m/\s/) {
  $cmd = $cmd[0];
  @cmd = split /\s+/, $cmd;
}

# Setup a die handler to just exec the given args on error
local $SIG{__DIE__} = sub { 
  die @_ if $^S;        # but don't exec inside an eval
  warn @_;
  exec(ref $cmd ? @$cmd : $cmd);
};

# Setup config etc.
my $config = Config::Tiny->read($config_file) if -f $config_file;
my $server = $config->{_}->{server} || $config->{_}->{cronologue_server} || 'localhost';
$stream ||= 1 if ($config->{_}->{record} || 'always') eq 'stream' && ! $always;
my $hostname = hostname;
(my $hostname_short = $hostname) =~ s/\..*$//;
my $user = getpwuid($>) || $>;
my $start = gmtime;
my $start_ts   = $start->strftime('%Y%m%d%H%M%S');
my $start_long = $start->strftime('%a %d %b %Y %H:%M:%S');
my $start_date = $start->strftime('%Y-%m-%d');
my $start_time = $start->strftime('%H:%M:%S');
my $cmdline = join ' ', @cmd;
my $cmd_basename = basename($cmd[0]);
my $cmd_digest = md5_hex $cmdline;

# Build base URL
my $host_url = sprintf "http://%s/cronologue/data/", $server;
my $url_path = sprintf "%s/%s_%s", $hostname_short, $start_ts, $cmd_digest;

my $ua = LWP::UserAgent->new;
$ua->env_proxy;

# Do a MKCOL on the top-level $host_url, if required
my $url = "$host_url$hostname_short/";
my $req = HTTP::Request->new( GET => $url );
my $res = $ua->request($req);
if ($res->code == 404) {
  print "+ host url $url not found - doing MKCOL\n" if $verbose;
  unless ($noop) {
    $req = HTTP::Request->new( MKCOL => $url );
    $res = $ua->request($req);
    die "MKCOL to $url failed: " . $res->status_line unless $res->is_success;
  }
}

my $job_url = "$host_url$url_path.txt";
print "+ job record url: $job_url\n" if $verbose;
my $record;

# PUT initial job record (unless $stream)
if (! $stream) {
  # Build initial output
  $record = <<EOD
Hostname:       $hostname_short
FQDN:           $hostname
Username:       $user
StartDatetime:  $start_long
StartDate:      $start_date
StartTime:      $start_time
CommandLine:    $cmdline
Command:        $cmd_basename
CommandDigest:  $cmd_digest
EOD
;

  # PUT initial job record
  unless ($noop) {
    $req = HTTP::Request->new( PUT => $job_url );
    $req->content_type('text/plain');
    $req->content($record);
    $res = $ua->request($req);
    die "PUT to $job_url failed: " . $res->status_line unless $res->is_success;
  }
}

# Run command
my $stdout = 'x' x 10_000; $stdout = '';        # preallocate 10k bytes
my $stderr = 'x' x 10_000; $stderr = '';        # preallocate 10k bytes
run3 $cmd, \undef, \$stdout, \$stderr;
my $rc = $? >> 8;
my $end = gmtime;
my $end_ts   = $end->strftime('%Y%m%d%H%M%S');
my $end_long = $end->strftime('%a %d %b %Y %H:%M:%S');
my $end_date = $end->strftime('%Y-%m-%d');
my $end_time = $end->strftime('%H:%M:%S');
my $runtime  = $end - $start;

# PUT stdout and stderr, if any
my $stdout_stderr = '';
if ($stdout ne '') {
  my $stdout_path = "$url_path.out";
  $stdout_stderr .= "Stdout:         $stdout_path\n";
  $stdout_stderr .= "StdoutSize:     " . length($stdout) . "\n";
  $url = $host_url . $stdout_path;
  print "+ stdout found, url: $url\n" if $verbose;
  unless ($noop) {
    $req = HTTP::Request->new( PUT => $url );
    $req->content_type('text/plain');
    $req->content($stdout);
    $res = $ua->request($req);
    die "PUT to $url failed: " . $res->status_line unless $res->is_success;
  }

  print $stdout if $passthru;
}
if ($stderr ne '') {
  my $stderr_path = "$url_path.err";
  $stdout_stderr .= "Stderr:         $stderr_path\n";
  $stdout_stderr .= "StderrSize:     " . length($stderr) . "\n";
  $url = $host_url . $stderr_path;
  print "+ stderr found, url: $url\n" if $verbose;
  unless ($noop) {
    $req = HTTP::Request->new( PUT => $url );
    $req->content_type('text/plain');
    $req->content($stderr);
    $res = $ua->request($req);
    die "PUT to $url failed: " . $res->status_line unless $res->is_success;
  }

  print STDERR $stderr if $passthru;
}

if (! $stream || $stdout_stderr) {
  $record = <<EOD
Hostname:       $hostname_short
FQDN:           $hostname
Username:       $user
StartDatetime:  $start_long
StartDate:      $start_date
StartTime:      $start_time
EndDatetime:    $end_long
EndDate:        $end_date
EndTime:        $end_time
JobDuration:    $runtime
CommandLine:    $cmdline
Command:        $cmd_basename
CommandDigest:  $cmd_digest
ReturnCode:     $rc
$stdout_stderr
EOD
;

  # PUT updated job record
  print "+ job record:\n$record" if $verbose >= 2 or $noop;
  unless ($noop) {
    $req = HTTP::Request->new( PUT => $job_url );
    $req->content($record);
    $res = $ua->request($req);
    die "PUT to $job_url failed: " . $res->status_line unless $res->is_success;
  }
}

__END__

=head1 NAME

cronologue is a cron logger that executes a command, and logs the output
streams and a job record back to a central log server.

=head1 SYNOPSIS

  cronologue [-a|-s] [-n] [-v] <cmd> <args>

=head1 DESCRIPTION

cronologue is a cron logger i.e. a wrapper that executes a command, capturing 
any stdout and stderr streams produced, and logs a job record and those output 
streams back to a central log server. Job records and output files are recorded 
as plain text files, and pushed to an apache web server via HTTP PUT.

=head2 CONFIG FILE

Some cronologue settings can be configured in a config file located in 
'/etc/cronologue.conf'. The default settings and file format is:

  # Web server to which we PUT job record and output text files
  server = localhost

  # When to create a job record [always|stream]
  # stream means only create a job record if there is stdout or stderr output
  record = always

=head2 OPTIONS

=over 4

=item --config | -c <config_file>

Use the specified config file instead of the default '/etc/cronologue.conf'.

=item --always | -a

Always log a job record, irrespective of whether any stdout or stderr streams 
are produced. Equivalent to 'record = always' in the cronologue config file, 
and overrides 'record = stream'.

=item --stream | -s

Only log a job record if any stdout or stderr output is produced by command.
Equivalent to 'record = stream' in the cronologue config file, and overrides
'record = always' (which is the default).

=item --noop | -n

Run the given command, but don't actually log any output back to the log server, 
just show what would be logged. Useful for testing. Implies --verbose.

=item --verbose | -v

Produce verbose output for debugging.

=back

=head1 AUTHOR

Gavin Carr <gavin@openfusion.com.au>

=head1 COPYRIGHT AND LICENCE

Copyright (C) Gavin Carr 2010. 

This library is free software; you can redistribute it and/or modify it 
under the same terms as Perl itself, either Perl version 5.8.0 or, at 
your option, any later version of Perl 5.

=cut


# vim:sw=2
